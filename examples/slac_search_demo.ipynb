{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191c5016",
   "metadata": {},
   "source": [
    "# ScienceSearch NLP Keywords with Visualization and Saving Results Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aae04e7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "#### Step 0: Import modules\n",
    "##### Step 1: Setup demo with database\n",
    "##### Step 2: Select which experiment you would like to run\n",
    "##### Step 3: Preprocess files \n",
    "##### Step 4: Train and run models\n",
    "##### Step 5: Visualize results in context of the input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470daf6",
   "metadata": {},
   "source": [
    "## Step 0: Import modules\n",
    "Import modules and set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from sciencesearch.nlp.hyper import Hyper, algorithms_from_results\n",
    "from sciencesearch.nlp.sweep import Sweep\n",
    "from sciencesearch.nlp.models import Rake, Yake, KPMiner, Ensemble\n",
    "from sciencesearch.nlp.train import train_hyper, load_hyper, run_hyper\n",
    "from sciencesearch.nlp.search import Searcher\n",
    "from operator import attrgetter\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "logging.root.setLevel(logging.ERROR)  # silence pke warnings\n",
    "slog = logging.getLogger(\"sciencesearch\")\n",
    "slog.setLevel(logging.WARNING)\n",
    "from sciencesearch.nlp.visualize_kws import JsonView\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2443c91b",
   "metadata": {},
   "source": [
    "## Step 1: Setup demo with database\n",
    "*This demo will only work if you are a SLAC employee with access to the correct data.*\n",
    "\n",
    "To begin, please download and add the private_data folder to the root directory `sciencesearch/`\n",
    "\n",
    "In this directory you will see\n",
    "1. The database shared with us\n",
    "2. An empty folder for results\n",
    "3. An empty folder depending on which experiment you are running \n",
    "3. A readme to explain which experiments can be run\n",
    "\n",
    "----\n",
    "Folders are as follows and will be populated with input files:\n",
    "\n",
    "- Experiment 1: `slac_logs`\n",
    "- Experiment 2: `descriptions`\n",
    "- Experiment 3: `params`\n",
    "- Experiment 4: `commentary`\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd9b923",
   "metadata": {},
   "source": [
    "## Step 2: Select which experiment you would like to run\n",
    "\n",
    "See README.md in the private directory folder for experiment descriptions,\n",
    "\n",
    "After selecting your experiment, determine the corresponding configuration file\n",
    "- Experiment 1: `slac_config_all_elogs.json`\n",
    "- Experiment 2: `slac_config_descriptions.json`\n",
    "- Experiment 3: `slac_config_params.json`\n",
    "- Experiment 4: `slac_config_commentary.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c9489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define config file's filepath \n",
    "config_fp = 'slac_config_all_elogs.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c3558c",
   "metadata": {},
   "source": [
    "#### Instructions to run your own experiment and create a custom configuration file\n",
    "Please see `examples/pipeline` for instructions to build a custom configuration file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c547f00",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess files \n",
    "Run preprocessing of data files such that all input files are saved according to the location and file type defined in your config file\n",
    "\n",
    "```\n",
    "\"training\": {\n",
    "        \"directory\": \"../private_data/{your_directory}\",\n",
    "        \"input_files\": [\"*.txt\"],\n",
    "}\n",
    "```\n",
    "Find subheading for the experiment you are running for preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31524bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from private_data.preprocessing.extract_data_from_db import DBDataExtractor\n",
    "\n",
    "# TODO: define fp for database \n",
    "db_path = 'simplified_elog.db'\n",
    "\n",
    "# Setup DBDataExtractor\n",
    "data_extractor = DBDataExtractor(db_filepath=db_path)\n",
    "\n",
    "# Preprocess files for experiment 1\n",
    "data_extractor.prepare_experiment1_data()\n",
    "\n",
    "# Preprocess files for experiment 2\n",
    "data_extractor.prepare_experiment2_data()\n",
    "\n",
    "\n",
    "# Preprocess files for experiment 3\n",
    "data_extractor.prepare_experiment3_data()\n",
    "\n",
    "# Preprocess files for experiment 4\n",
    "data_extractor.prepare_experiment4_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680717a",
   "metadata": {},
   "source": [
    "##### Experiment 1: Extract keywords from all experiment logs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f0b807",
   "metadata": {},
   "source": [
    "##### Experiment 3: Extract keywords from experiment descriptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e25c71",
   "metadata": {},
   "source": [
    "##### Experiment 3: Extract keywords from all experiment logs regarding paramaters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f048f5",
   "metadata": {},
   "source": [
    "##### Experiment 4: Extract keywords from all experiment logs that do not regard parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236dc56",
   "metadata": {},
   "source": [
    "## Step 4: Train and run models\n",
    "In this example, we pick the 'best' result for each algorithm by training on two files with some user-provided keywords.\n",
    "Then we extract keywords from a third file using the trained model.\n",
    "\n",
    "Using a searcher which will read in training data from a search configuration, select the best model's keywords. \n",
    "We save the results of the hyperparameter training in a serialize Python \"pickle\" file so we don't need to repeat the training.\n",
    "We could run the same hyperparameters on multiple files without retraining with `run_hyper()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: If you would like to re-train the model, delete `private_data/{training_directory}/{save_file}.pkl`\n",
    "\n",
    "# Create a Searcher object from the configuration\n",
    "slac_searcher = Searcher.from_config(config_file=config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6ab34",
   "metadata": {},
   "source": [
    "### With Searcher object, search for all files that have a certain keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98408751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files that have a keyword\n",
    "# TODO: set keyword variable to a keyword you would like to look for\n",
    "keyword = \"diffraction\"\n",
    "slac_searcher.find(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1e659-960d-42cc-ad55-f6d9d7f99eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see all file keywords (predicted and training)\n",
    "# slac_searcher.file_keywords\n",
    "\n",
    "# see all predicted keywords\n",
    "# predicted_keywords = slac_searcher.predicted_keywords\n",
    "# predicted_keywords\n",
    "\n",
    "# see training keywords\n",
    "# slac_searcher.training_keywords\n",
    "# training_keywords\n",
    "\n",
    "# see separated training keywords and predicted keywords\n",
    "all_keywords = slac_searcher.training_and_predicted_keywords()\n",
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = all_keywords\n",
    "\n",
    "rows = []\n",
    "for name, conditions in data.items():\n",
    "    print(data)\n",
    "    row = {'experiment_name': name}\n",
    "    row.update(conditions)\n",
    "    rows.append(row)\n",
    "\n",
    "# TODO: define save file name and location\n",
    "file_name = 'results'\n",
    "\n",
    "\n",
    "# Create df and save to CSV\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(f'../private_data/results/{file_name}.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e0891",
   "metadata": {},
   "source": [
    "## Step 5: Visualize results in context of the input file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c245e3-41ba-4828-9853-8410dcd5c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view keywords in context of text logs (single file)\n",
    "# TODO: set file name to {experiment_id}.txt\n",
    "filename = \"test.txt\"\n",
    "HTML(\n",
    "    slac_searcher.view_keywords(\n",
    "        show_training=True, show_predicted=True, textfilename=filename\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef041bd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "# view keywords in context of text logs (all files)\n",
    "HTML(\n",
    "    slac_searcher.view_keywords(\n",
    "        show_training=True, show_predicted=True, textfilename=None\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
