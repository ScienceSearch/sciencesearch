{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191c5016",
   "metadata": {},
   "source": [
    "# ScienceSearch NLP Keywords with Visualiztion and Saving Results Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f470daf6",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "Import modules and set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82af33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from sciencesearch.nlp.hyper import Hyper, algorithms_from_results\n",
    "from sciencesearch.nlp.sweep import Sweep\n",
    "from sciencesearch.nlp.models import Rake, Yake, KPMiner, Ensemble\n",
    "from sciencesearch.nlp.train import train_hyper, load_hyper, run_hyper\n",
    "from sciencesearch.nlp.search import Searcher\n",
    "from operator import attrgetter\n",
    "# logging\n",
    "import logging\n",
    "logging.root.setLevel(logging.ERROR)  # silence pke warnings\n",
    "slog = logging.getLogger(\"sciencesearch\")\n",
    "slog.setLevel(logging.WARNING)\n",
    "from sciencesearch.nlp.visualize_kws import JsonView\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff369f4",
   "metadata": {},
   "source": [
    "## Generate a tuned algorithm for extracting keywords\n",
    "First step is to tune the parameters of the available algorithms to the particular type of text that will be processed. This is best done by providing some \"gold standard\" keywords for sample documents, then allowing the system to run combinations of parameters to experimentally see which comes closest to generating the same keywords automatically. Our approach here will be to run 3 different NLP algorithms -- Rake, Yake, and KPMiner -- across a variety of settings, and pick all combinations that come close to the \"best\" F1 score. These algorithm/parameter combinations will be encapsulated in an \"ensemble\" algorithm that will take the union of the keywords generated by each individual algorithm.\n",
    "\n",
    "Note: The F1 score balances two performance metrics: precision and recall. In terms of this case, precision is the proportion of keywords generated that match the gold standard, and recall is the proportion of the gold standard keywords that were generated at all. Since these two metrics tend to vary inversely (in particular, generating _lots_ of keywords tends to give good recall but poor precision) the F1 tries to balance them by taking their harmonic mean. The result is that, roughly speaking, the F1 reflects the lower of the two scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082857ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter = Hyper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f97c562",
   "metadata": {},
   "source": [
    "## Set up parameter sweeps\n",
    "The `Sweep` class from the `sciencesearch.nlp.sweep` module is used to configure the algorithm and range of parameters to use in the hyperparameter tuning.\n",
    "The list of possible parameters is shown with the `.print_params` method of each algorithm class. Note that these include a set of parameters shared across all the algorithms, for which there are reasonable defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d48b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yake.print_params()\n",
    "sweep = Sweep(alg=Yake)\n",
    "sweep.set_param_range(\"ws\", lb=1, ub=3, step=1)\n",
    "sweep.set_param_discrete(\"dedup\", [0.8, 0.9, 0.95])\n",
    "sweep.set_param_discrete(\"dedup_method\", [\"leve\", \"seqm\"]) # jaro\n",
    "hyperparameter.add_sweep(sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34c3fd",
   "metadata": {},
   "source": [
    "Common:\n",
    "  - Stopwords stopwords: Stopwords. Default is None\n",
    "  - bool stemming: Whether to do stemming. Default is False\n",
    "  - int num_keywords: How many keywords to extract. Default is 10\n",
    "  - list keyword_sort: sort orderings: occ (number of occurrences), score, or a dict with weights for each of these keys, e.g., {'occ': 0.75, 'score': 0.25}, and additionally a flag 'i' for ignoring keyword case. Default is []\n",
    "Yake:\n",
    "  - int ws: YAKE window size. Default is 2\n",
    "  - float dedup: Deduplication limit for YAKE. Default is 0.9\n",
    "  - str dedup_method: method ('leve', 'seqm' or 'jaro'). Default is leve\n",
    "  - int ngram: Maximum ngram size. Default is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596ab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rake.print_params()\n",
    "sweep = Sweep(alg=Rake)\n",
    "sweep.set_param_range(\"min_len\", lb=1, ub=1, step=1)\n",
    "sweep.set_param_range(\"max_len\", lb=1, ub=3, step=1)\n",
    "sweep.set_param_range(\"min_kw_occ\", lb=1, ub=10, step=1)\n",
    "sweep.set_param_discrete(\"include_repeated_phrases\", [False, True])\n",
    "hyperparameter.add_sweep(sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04fc1c",
   "metadata": {},
   "source": [
    "Common:\n",
    "  - Stopwords stopwords: Stopwords. Default is None\n",
    "  - bool stemming: Whether to do stemming. Default is False\n",
    "  - int num_keywords: How many keywords to extract. Default is 10\n",
    "  - list keyword_sort: sort orderings: occ (number of occurrences), score, or a dict with weights for each of these keys, e.g., {'occ': 0.75, 'score': 0.25}, and additionally a flag 'i' for ignoring keyword case. Default is []\n",
    "Rake:\n",
    "  - int min_len: Minimum ngram size. Default is 1\n",
    "  - int max_len: Maximum ngram size. Default is 3\n",
    "  - int min_kw_len: Minimum keyword length. Applied as post-processing filter.. Default is 3\n",
    "  - int min_kw_occ: Mimumum number of occurences of keyword in text string.Applied as post-processing filter.. Default is 4\n",
    "  - Any ranking_metric: ranking parameter for rake algorithm. Default is Metric.DEGREE_TO_FREQUENCY_RATIO\n",
    "  - bool include_repeated_phrases: boolean for determining whether multiple of the same keywords are output by rake. Default is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df79bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "KPMiner.print_params()\n",
    "sweep = Sweep(alg=KPMiner)\n",
    "sweep.set_param_range(\"lasf\", lb=1, ub=3, step=1)\n",
    "# zomg this takes forever..\n",
    "#sweep.set_param_range(\"cutoff\", lb=200, ub=1300, nsteps=5)\n",
    "#sweep.set_param_range(\"alpha\", lb=3.0, ub=4.0, step=0.2)\n",
    "#sweep.set_param_range(\"sigma\", lb=2.6, ub=3.2, step=0.2)\n",
    "hyperparameter.add_sweep(sweep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b68183",
   "metadata": {},
   "source": [
    "Common:\n",
    "  - Stopwords stopwords: Stopwords. Default is None\n",
    "  - bool stemming: Whether to do stemming. Default is False\n",
    "  - int num_keywords: How many keywords to extract. Default is 10\n",
    "  - list keyword_sort: sort orderings: occ (number of occurrences), score, or a dict with weights for each of these keys, e.g., {'occ': 0.75, 'score': 0.25}, and additionally a flag 'i' for ignoring keyword case. Default is []\n",
    "KPMiner:\n",
    "  - int lasf: Last allowable seen frequency. Default is 3\n",
    "  - int cutoff: Cutoff threshold for number of words after which if a phrase appears for the first time it is ignored. Default is 400\n",
    "  - float alpha: Weight-adjustment parameter 1 for boosting factor.See original paper for definition. Default is 2.3\n",
    "  - float sigma: Weight-adjustment parameter 2 for boosting factor.See original paper for definition. Default is 3.0\n",
    "  - object doc_freq_info: Document frequency counts. Default (None) uses the semeval2010 countsprovided in 'df-semeval2010.tsv.gz'. Default is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db528d24",
   "metadata": {},
   "source": [
    "### Create configuration to automatically train and build a Searcher object that allows you to find files by their predicted and gold keywords\n",
    "\n",
    "See example:  examples/search-vis-demo-config\n",
    "\n",
    "To use existing configuration:\n",
    "1. Add input files to `private_data/slac_logs'\n",
    "2. Add training keyword file to slac_keywords.csv\n",
    "    - the format is `filename`, `\"list, of, keywords, as, a, comma, separated, string\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f9457",
   "metadata": {},
   "source": [
    "#### Understanding the config file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239fab6",
   "metadata": {},
   "source": [
    "\n",
    "##### Section 1: should include algorithms: Yake, Rake, and/or KPMiner\n",
    "\n",
    "In `algorithms` include:\n",
    "- `yake`\n",
    "    - `module`: `sciencesearch.nlp.models`\n",
    "    - `class`: `Yake`\n",
    "- `rake`\n",
    "    - `module`: `sciencesearch.nlp.models`\n",
    "    - `class`: `Rake`\n",
    "- `kpminer`\n",
    "    - `module`: `sciencesearch.nlp.models`\n",
    "    - `class`: `KPMiner`\n",
    "\n",
    "<details> <summary>Example</summary>\n",
    "  \n",
    "```json\n",
    "\"algorithms\": {\n",
    "        \"yake\": {\n",
    "            \"module\": \"sciencesearch.nlp.models\",\n",
    "            \"class\": \"Yake\"\n",
    "        },\n",
    "        \"rake\": {\n",
    "            \"module\": \"sciencesearch.nlp.models\",\n",
    "            \"class\": \"Rake\"\n",
    "        },\n",
    "        \"kpminer\": {\n",
    "            \"module\": \"sciencesearch.nlp.models\",\n",
    "            \"class\": \"KPMiner\"\n",
    "        }\n",
    "    },\n",
    "    ```\n",
    "    </details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6681ccc8",
   "metadata": {},
   "source": [
    "##### Section 2: Define potential hyperparameter combinations\n",
    "\n",
    "See `Set up parameter sweeps` for details\n",
    "\n",
    "<details> <summary>Example</summary>\n",
    "  \n",
    "``` json\n",
    "\"sweeps\": {\n",
    "        \"kpminer\": {\n",
    "            \"lasf\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 1,\n",
    "                \"ub\": 3,\n",
    "                \"step\": 1\n",
    "            },\n",
    "            \"-cutoff\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 200,\n",
    "                \"ub\": 1300,\n",
    "                \"nsteps\": 5\n",
    "            },\n",
    "            \"-alpha\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 3.0,\n",
    "                \"ub\": 4.0,\n",
    "                \"step\": 0.2\n",
    "            },\n",
    "            \"sigma\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 2.8,\n",
    "                \"ub\": 3.0,\n",
    "                \"step\": 0.2\n",
    "            }\n",
    "        }\n",
    "        \"rake\": {\n",
    "            \"min_len\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 1,\n",
    "                \"ub\": 1,\n",
    "                \"step\": 1\n",
    "            },\n",
    "            \"max_len\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 1,\n",
    "                \"ub\": 3,\n",
    "                \"step\": 1\n",
    "            },\n",
    "            \"min_kw_occ\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 1,\n",
    "                \"ub\": 10,\n",
    "                \"step\": 1\n",
    "            },\n",
    "            \"include_repeated_phrases\": {\n",
    "                \"_type\": \"discrete\",\n",
    "                \"values\": [false, true]\n",
    "            }\n",
    "        },\n",
    "        \"yake\": {\n",
    "            \"ws\": {\n",
    "                \"_type\": \"range\",\n",
    "                \"lb\": 1,\n",
    "                \"ub\": 3,\n",
    "                \"step\": 1\n",
    "            },\n",
    "            \"dedup\": {\n",
    "                \"_type\": \"discrete\",\n",
    "                \"values\": [0.8, 0.9, 0.95]\n",
    "            },\n",
    "            \"dedup_method\": {\n",
    "                \"_type\": \"discrete\",\n",
    "                \"values\": [\"leve\", \"seqm\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "```\n",
    " <details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc2abe",
   "metadata": {},
   "source": [
    "##### Section 3: Define filepaths to training data, etc\n",
    "\n",
    "In `training` include: \n",
    "- `directory`: Base directory containing training data\n",
    "- `input_files`: global pattern for input text files\n",
    "- `keywords`: CSV file containing training keywords\n",
    "- `epsilon`: Learning rate or noise parameter for training\n",
    "- `save_file`: Output file for trained model or hyperparameters\n",
    "\n",
    "\n",
    "<details> <summary>Example</summary>\n",
    "  \n",
    "``` json\n",
    "\"training\": {\n",
    "        \"directory\": \"../private_data/slac_logs\",\n",
    "        \"input_files\": [\"*.txt\"],\n",
    "        \"keywords\": [\"slac_keywords.csv\"],\n",
    "        \"epsilon\": 0.05,\n",
    "        \"save_file\": \"slac_hyper.pkl\"\n",
    "    },\n",
    "```\n",
    " <details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef131f2",
   "metadata": {},
   "source": [
    "##### Section 4: Define filepaths to saving filwpaths\n",
    "\n",
    "In `saving` include: \n",
    "- `ouput_files_directory`: Output file directory for search results\n",
    "- `css_filepath`: Filepath to styling for highlighted text HTML\n",
    "\n",
    "<details> <summary>Example</summary>\n",
    "  \n",
    "``` json\n",
    "\"saving\": {\n",
    "        \"css_filepath\": \"../../shared/keyword_vis.css\",\n",
    "        \"output_files_directory\": \"../private_data/results\"\n",
    "    }\n",
    "```\n",
    " <details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236dc56",
   "metadata": {},
   "source": [
    "## Train and run models\n",
    "In this example, we pick the 'best' result for each algorithm by training on two files with some user-provided keywords.\n",
    "Then we extract keywords from a third file using the trained model.\n",
    "\n",
    "Using a searcher which will read in training data from a search configuration, select the best model's keywords. \n",
    "We save the results of the hyperparameter training in a serialize Python \"pickle\" file so we don't need to repeat the training.\n",
    "We could run the same hyperparameters on multiple files without retraining with `run_hyper()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5e49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Enter filepath to your configuration\n",
    "config_fp = \"slac_config.json\"\n",
    "\n",
    "# TODO: If you would like to re-train the model, delete `private_data/slac_logs/slac_hyper.pkl`\n",
    "\n",
    "# Create a Searcher object from the configuration \n",
    "slac_searcher = Searcher.from_config(config_file=config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e6ab34",
   "metadata": {},
   "source": [
    "### With Searcher object, search for all files that have a certain keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98408751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all files that have a keyword\n",
    "keyword = \"test\"\n",
    "slac_searcher.find(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928712c0",
   "metadata": {},
   "source": [
    "### Create JsonVisualizer object with Searcher object\n",
    "\n",
    "With JsonVisualizer, you can \n",
    "1. Save predicted, or training keywords as a json file\n",
    "2. Create a text HTML file with keywords highlighted in the context of the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898b7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slac_json_viewer = JsonView(searcher=slac_searcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90758aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "slac_json_viewer.predicted_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d318187a",
   "metadata": {},
   "source": [
    "#### Save and visualize a single set of keywords\n",
    "\n",
    "In this example, predicted keywords are saved, and the resulting saved json is visualized as a html page per input file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dfe4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save keywords\n",
    "slac_json_viewer.save_predicted_keywords(filename = '../private_data/results/predicted_keywords.json')\n",
    "\n",
    "# open HTML to see keywords in context of the file's text\n",
    "JsonView.visualize_from_config(config_file=config_fp, json_file=\"predicted_keywords.json\", save_filename=\"predicted_keywords_html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb2eb5",
   "metadata": {},
   "source": [
    "#### Save and visualize multiple sets of keywords\n",
    "\n",
    "In this example, predicted keywords and training keywords are saved, and the resulting saved json is visualized as a html page per input file, color coded to differentiate each set of keywords with a key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ec8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slac_json_viewer.save_all_keyword_sets('../private_data/results/keywords_all_sets.json')\n",
    "JsonView.visualize_from_config(config_file=config_fp,json_file=\"keywords_all_sets.json\", save_filename=\"keywords_all_sets_html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
