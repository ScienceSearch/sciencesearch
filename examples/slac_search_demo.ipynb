{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57515761",
   "metadata": {},
   "source": [
    "## __Notebook to Reproduce Results and Run Experiments__\n",
    "\n",
    "### Steps for reproducing results  \n",
    "- Step 0: Import modules\n",
    "\n",
    "- Step 1: Setup demo with database\n",
    "\n",
    "- Step 2: Select which experiment you would like to run\n",
    "\n",
    "- Step 3: Preprocess files \n",
    "\n",
    "- Step 4: Train and run models\n",
    "\n",
    "- Step 5: Visualize results in context of the input file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f9b40f",
   "metadata": {},
   "source": [
    "### Step 0: Import modules\n",
    "Import modules and set up logging\n",
    "See [documentation](https://deepwiki.com/ScienceSearch/sciencesearch/1-overview) for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pathlib import Path\n",
    "from sciencesearch.nlp.hyper import Hyper, algorithms_from_results\n",
    "from sciencesearch.nlp.sweep import Sweep\n",
    "from sciencesearch.nlp.models import Rake, Yake, KPMiner, Ensemble\n",
    "from sciencesearch.nlp.train import train_hyper, load_hyper, run_hyper\n",
    "from sciencesearch.nlp.search import KeywordExplorer\n",
    "from operator import attrgetter\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "\n",
    "logging.root.setLevel(logging.ERROR)  # silence pke warnings\n",
    "slog = logging.getLogger(\"sciencesearch\")\n",
    "slog.setLevel(logging.WARNING)\n",
    "from sciencesearch.nlp.visualize_kws import JsonView\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e342621",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831dfdc3",
   "metadata": {},
   "source": [
    "### Step 1: Setup demo with database\n",
    "*This demo will only work if you are a SLAC employee with access to the correct data.*\n",
    "\n",
    "***\n",
    "\n",
    "To begin, please create a `private_data` folder in the root directory `sciencesearch/` \n",
    "\n",
    "In the `private_data` folder add a database source\n",
    "\n",
    "\n",
    "*Note: This code is generalizable to any database with  `logbook` and `experiments` tables (See structure in `simplified_elog.db`)*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c58ff5",
   "metadata": {},
   "source": [
    "### Step 2: Select a source to extract keywords\n",
    "\n",
    "Extract keywords from:\n",
    "\n",
    "1. All experiment logs (elogs)\n",
    "2. Only experiment descriptions\n",
    "3. Only elogs with experiment parameters\n",
    "4. Only elogs that are misc. commentary\n",
    "\n",
    "See README.md for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select an experiment to run\n",
    "source = 4\n",
    "\n",
    "source_configs = {\n",
    "    1: \"slac_config_all_elogs.json\",\n",
    "    2: \"slac_config_descriptions.json\",\n",
    "    3: \"slac_config_params.json\",\n",
    "    4: \"slac_config_commentary.json\"\n",
    "}\n",
    "\n",
    "# Set config filepath \n",
    "config_fp = f'config_files/{source_configs[source]}'\n",
    "config_fp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543705dd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b573a17",
   "metadata": {},
   "source": [
    "### Step 3: Set up config and preprocess files \n",
    "\n",
    "The filepath to your database should be specified in the configuration\n",
    "\n",
    "```\n",
    "\"database\": \"private_data/{database_name}.db\"\n",
    "```\n",
    "\n",
    "\n",
    "Preprocessed files will be saved as `[.txt]` files in the directory specified in the config.\n",
    "\n",
    "This need not be updated.\n",
    "\n",
    "```\n",
    "\"training\": {\n",
    "        \"directory\": \"../private_data/{custom_directory}\",\n",
    "        \"input_files\": [\"*.txt\"],\n",
    "}\n",
    "```\n",
    "#### Run preprocessing of data files for the selected experiemnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4fc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sciencesearch.nlp.slac_data_extractor import SLACDatabaseDataExtractor\n",
    "\n",
    "# Setup DBDataExtractor\n",
    "data_extractor = SLACDatabaseDataExtractor(config_file=config_fp)\n",
    "data_extractor.get_tables()\n",
    "# Run the corresponding data extraction and cleaning methods based on your experiment type\n",
    "if source == 1:\n",
    "    \"\"\" Preprocess files for experiment 1\n",
    "    results will be saved in private_data/slac_logs\"\"\"\n",
    "    data_extractor.process_elogs()\n",
    "\n",
    "elif source == 2:\n",
    "    \"\"\" Preprocess files for experiment 2\n",
    "    results will be saved in private_data/descriptions \"\"\"\n",
    "    data_extractor.process_experiment_descriptions()\n",
    "\n",
    "elif source == 3:\n",
    "    \"\"\" Preprocess files for experiment 3\n",
    "    results will be saved in private_data/params \"\"\"\n",
    "    data_extractor.process_experiment_elog_parameters()\n",
    "\n",
    "elif source == 4:\n",
    "    \"\"\" Preprocess files for experiment 4\n",
    "    results will be saved in private_data/commentary \"\"\"\n",
    "    data_extractor.process_experiment_elog_commentary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cdd4d8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4cc2f",
   "metadata": {},
   "source": [
    "### Step 4: Train and run models\n",
    "\n",
    "When a KeywordExtractor object is created with a configuration file it:\n",
    "\n",
    "1. Reads in training data from a search configuration\n",
    "\n",
    "2. Hyperparameter optimization: compares many algorithm parameters to select the highest performing algorithm settings\n",
    "\n",
    "3. Trains models according to the 'best' hyperparameters \n",
    "\n",
    "4. Extracts keywords using the trained models\n",
    "\n",
    "\n",
    "We save the models in a serialized Python \"pickle\" file so we don't need to repeat the training.\n",
    "\n",
    "We could use the same models on multiple files without retraining with `run_hyper()`\n",
    "\n",
    "*Note: if you would like to re-train the model, delete `private_data/{training_directory}/{save_file}.pkl*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27942a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a KeywordExplorer object from the configuration\n",
    "slac_searcher = KeywordExplorer.from_config(config_file=config_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f39fd5",
   "metadata": {},
   "source": [
    "#### Explore keyword results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "### See all file keywords (predicted and training)\n",
    "# slac_searcher.file_keywords\n",
    "\n",
    "### See all predicted keywords\n",
    "# predicted_keywords = slac_searcher.predicted_keywords\n",
    "\n",
    "### See training keywords\n",
    "# slac_searcher.training_keywords\n",
    "\n",
    "# See both training keywords and predicted keywords\n",
    "slac_searcher.training_and_predicted_keywords()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f4a74",
   "metadata": {},
   "source": [
    "#### Search for all experiments that have a particular keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d75198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set keyword variable to a keyword you would like to look for\n",
    "\n",
    "keyword = \"magnet\"\n",
    "slac_searcher.find(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e7192",
   "metadata": {},
   "source": [
    "#### Save keywords\n",
    "Location for results is defined in the configuration file. \n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "\"saving\": {\n",
    "        \"css_filepath\": \"../../shared/keyword_vis.css\",\n",
    "        \"output_files_directory\": \"../private_data/results\"\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define save file name\n",
    "file_name = f\"experiment_{source}_results\"\n",
    "slac_searcher.save_keywords_to_file(file_name = file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affad275",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2b46e",
   "metadata": {},
   "source": [
    "### Step 5: Visualize keywords\n",
    "\n",
    "Highlight the keywords in the input file (HTML)\n",
    "\n",
    "Options include \n",
    "\n",
    "(1) View training and/or predicted keywords\n",
    "\n",
    "(2) Seeing one or all files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e914a059",
   "metadata": {},
   "source": [
    "#### Visualize keywords: Single file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b231d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: set file name to {experiment_id}.txt\n",
    "filename = \"test.txt\"\n",
    "HTML(\n",
    "    slac_searcher.view_keywords(\n",
    "        show_training=True, show_predicted=True, textfilename=filename\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca5fed",
   "metadata": {},
   "source": [
    "#### Visualize keywords: All files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "# View keywords in context of text logs (all files)\n",
    "HTML(\n",
    "    slac_searcher.view_keywords(\n",
    "        show_training=True, show_predicted=True, textfilename=None\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
